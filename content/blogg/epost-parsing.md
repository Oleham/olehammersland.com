+++
title = "Parsing av e-poster üìÆ"
date = "2021-02-16T18:31:38+01:00"

#
# description is optional
#
# description = "Jeg automatiserer lesing av e-poster for en kunde. BeautifulSoup og Mailparser. Spare tid og klikk p√• √• automatisere e-postlesing"

tags = ["automatisering","bash","effektivisering","python",]
+++

Det er ikke alltid mulig √• arbeide p√• en s√• effektiv m√•te som mulig. Ofte m√• man samarbeide med organisasjoner med en egen arbeidsflyt og kultur som ikke n√∏dvendigvis er forenlig med hurtig arbeid. 

**To av verstingene de fleste oversettere blir tvunget til √• bale med, er e-post og Excel-regneark.** Det er ikke s√• rart. For flere kunder som ikke n√∏dvendigvis er s√• teknisk kompetente, fremst√•r Excel som grei m√•te √• organisere tekst p√•. P√• samme m√•te er e-post en rask og umiddelbar m√•te √• sende ut en fil n√•r det ikke er noen etablert teknisk infrastruktur p√• plass enn√•. Men det er ikke noen solid m√•te √• arbeide p√•. Det er mange ulemper ved √• distribuere filer p√• e-post:

* oversikt
* kapasitet (mental og kronisk)
* stress

Det f√∏rste punktet gjelder oversikt: til tross for at jeg har jobbet mye med e-post, f√∏ler jeg fortsatt ikke at jeg helt har knekket koden for hvordan man skal sortere e-poster s√• effektivt som mulig. Spesielt n√•r man ogs√• skal sortere flere kunder, flere kontaktpersoner og flere filer. Det har hendt meg at jeg har oversatt feil fil fordi jeg p√• samme tid fikk to filer tilsendt med tiln√¶rmet samme navn.

Det at det tar tid √• sortere e-post, lagre vedlegg og vedlikeholde mappestrukturer, er ogs√• ganske opplagt.

Balingen med e-post koster ogs√• mental *kapasitet*. Man er n√∏dt til √• konsentrere seg, holde tunga rett i munnen og bruke tid p√• √• sortere og finne frem til riktig filer. Det er dessuten et *stressmoment* som henter meg ut av flytsonen jeg helst vil v√¶re i n√•r jeg oversetter.
Dessuten er det vel nok rapporter n√• om at for mange e-poster ikke er bra for mental helse. Likevel...

## Noen kunder elsker e-post

Det er bare √• feise fakta. Som en stakkars frilanser er jeg jo der for √• oppfylle kundens behov. Da er det flaks at man kan tenne lys i stedet for √• forbanne m√∏rket ‚Äì ved √• l√¶re seg programmering.

Her vil jeg vise frem to Python-skript jeg har for √• forenkle arbeidet med en kunde. Det er en stor kunde med et stort markedsf√∏ringsapparat: nyhetsbrev, bannere, TV-reklamer, you name it. 
De sender meg ca. 15 e-poster daglig. Hver av disse e-postene inneholder et sted mellom 4 og 50 bilder (jpg eller gif). Bildene inneholder et f√∏rste utkast av det grafiske innholdet p√• opptil 6 forskjellige spr√•k. Min jobb er √• se p√• vedleggene med de norske layoutene og lese den norske teksten.

Det √• lese gjennom bildene for √• lete etter feil tar, ikke s√• lang tid. Men det √• lese gjennom listen over vedlegg for √• finne de som er relevante for meg, tar litt tid. Heldigvis kan det automatiseres med Python üêç.

## Parsing med mailparser

Ved hjelp av [mailparser-biblioteket til Python](https://pypi.org/project/mail-parser/1.2.2/) har jeg derfor raskt laget et skript som:

1. Leter gjennom alle e-poster i samme mappe.
2. Sorterer alle vedlegg etter avsender og e-post.
3. Sletter alle som ikke er markert med NO for norsk.

Slik ser det ut:

```python
import os, mailparser, re

# Loops over emails in current directory
for raw_mail in os.listdir():

    # Unpack all files except the python files.
    # It is assumed that the current directory only contains emails
    if not raw_mail.endswith(".py") and os.path.isfile(raw_mail):

        # Extract sender and subject from email
        epost_obj = mailparser.parse_from_file(raw_mail)
        sender = epost_obj.from_[0][1]
        subject = epost_obj.subject
        new_subject = re.sub(r"\W", "", subject)

        # Create a folder structure based on sender and subject
        image_path = os.path.join(sender, new_subject)
        os.makedirs(image_path, exist_ok=True)

        # Write all attachments to the corresponding folder
        epost_obj.write_attachments(image_path)

        # Delete all files that don't contain NO in title
        for attach in os.listdir(image_path):
            if "_no." in attach or "NO" in attach:
                continue
            else:
                os.remove(os.path.join(image_path,attach))
    
```

Ikke et veldig elegant og effektivt skript, men det er en fin quick fix som finner frem alle de bildene jeg trenger fra 15 eposter og 100 vedlegg i l√∏pet av f√• sekunder.

## E-poster fra Google Drive

Den nevnte kunden sender ogs√• en god del e-poster fra Google Drive. I prinsippet fungerer det p√• samme m√•te, men disse epostene inneholder opptil 80‚Äì90 lenker i stedet for vedlegg. Av disse skal jeg klikke p√• de som inneholder norsk tekst (ca. 10 %).

Quick-fix-l√∏sningen p√• det ble √• lagre epostene som HTML-filer og skrive et raskt skript som bruker [Python-biblioteket BeautifulSoup](https://pypi.org/project/beautifulsoup4/) til √• parse HTML. Skriptet henter ut alle lenkene og √•pner dem i nettleseren dersom de slutter p√• "_no.gif" eller "_no.jpg".

```python
import bs4, sys, webbrowser

# Enter name of HTML email as CL argument
if len(sys.argv) != 2:
	print("Usage: python get_no_links.py <name of file>")
	sys.exit()

filename = sys.argv[1]

with open(filename) as f:
	soup = bs4.BeautifulSoup(f, "lxml")

# Find all anchor tags in HTML
lenker = soup.find_all("a")

# Loop over all anchor tags
for lenk in lenker:
    try:
		proofname = lenk.span.text
	except:
		continue

    # Open all links which ends with "no.gif" or "no.jpg" in web browser
	if proofname.endswith("no.gif") or proofname.endswith("no.jpg"):
		print("Opened " + proofname)
		webbrowser.open(lenk.get("href"))

```
